{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbp.entity.artifact_entity import DataIngestionArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/config/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ROOT_DIR = os.getcwd()\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbp.component.data_ingestion import DataIngestion\n",
    "from cbp.config.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion = Configuration(ROOT_DIR)\n",
    "data_ingestion_config = data_ingestion.get_data_ingestion_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataIngestionConfig(dataset_download_url='https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz', tgz_download_dir='/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/tgz_data', raw_data_dir='/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/raw_data', ingested_train_dir='/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/ingested_data/train', ingested_test_dir='/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/ingested_data/test')\n"
     ]
    }
   ],
   "source": [
    "print(data_ingestion_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion = DataIngestion(data_ingestion_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "HousingException",
     "evalue": "\n        Error occured in script: \n        [ /config/workspace/cbp/component/data_ingestion.py ] at \n        try block line number: [116] and exception block line number: [120] \n        error message: [\n        Error occured in script: \n        [ /config/workspace/cbp/component/data_ingestion.py ] at \n        try block line number: [29] and exception block line number: [41] \n        error message: [[Errno 21] Is a directory: '/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/tgz_data']\n        ]\n        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/cbp/component/data_ingestion.py:29\u001b[0m, in \u001b[0;36mDataIngestion.download_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(tgz_download_dir):\n\u001b[0;32m---> 29\u001b[0m     os\u001b[39m.\u001b[39;49mremove(tgz_download_dir)\n\u001b[1;32m     31\u001b[0m os\u001b[39m.\u001b[39mmakedirs(tgz_download_dir,exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/tgz_data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHousingException\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/cbp/component/data_ingestion.py:116\u001b[0m, in \u001b[0;36mDataIngestion.initiate_data_ingestion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     tgz_file_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_data()\n\u001b[1;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_tgz_file(tgz_file_path)\n",
      "File \u001b[0;32m~/workspace/cbp/component/data_ingestion.py:41\u001b[0m, in \u001b[0;36mDataIngestion.download_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mraise\u001b[39;00m HousingException(e,sys) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mHousingException\u001b[0m: \n        Error occured in script: \n        [ /config/workspace/cbp/component/data_ingestion.py ] at \n        try block line number: [29] and exception block line number: [41] \n        error message: [[Errno 21] Is a directory: '/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/tgz_data']\n        ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHousingException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_ingestion_artifact \u001b[38;5;241m=\u001b[39m \u001b[43mdata_ingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_data_ingestion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/cbp/component/data_ingestion.py:120\u001b[0m, in \u001b[0;36mDataIngestion.initiate_data_ingestion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_data_as_train_test()\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mraise\u001b[39;00m HousingException(e,sys) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mHousingException\u001b[0m: \n        Error occured in script: \n        [ /config/workspace/cbp/component/data_ingestion.py ] at \n        try block line number: [116] and exception block line number: [120] \n        error message: [\n        Error occured in script: \n        [ /config/workspace/cbp/component/data_ingestion.py ] at \n        try block line number: [29] and exception block line number: [41] \n        error message: [[Errno 21] Is a directory: '/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/tgz_data']\n        ]\n        "
     ]
    }
   ],
   "source": [
    "data_ingestion_artifact = data_ingestion.initiate_data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionArtifact(train_file_path='/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/ingested_data/train/housing.csv', test_file_path='/config/workspace/cbp/artifact/data_ingestion/2022-12-03-22-34-12/ingested_data/test/housing.csv', is_ingested=True, message='Data ingestion completed successfully.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ingestion_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = pd.read_csv(data_ingestion_artifact.train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data  = pd.read_csv(data_ingestion_artifact.test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbp.util.util import  read_yaml_file\n",
    "configuration = Configuration(ROOT_DIR)\n",
    "data_validation_config = configuration.get_data_validation_config(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_file_obj = read_yaml_file(data_validation_config.schema_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': {'longitude': 'float',\n",
       "  'latitude': 'float',\n",
       "  'housing_median_age': 'float',\n",
       "  'total_rooms': 'float',\n",
       "  'total_bedrooms': 'float',\n",
       "  'population': 'float',\n",
       "  'households': 'float',\n",
       "  'median_income': 'float',\n",
       "  'median_house_value': 'float',\n",
       "  'ocean_proximity': 'category'},\n",
       " 'numerical_columns': ['longitude',\n",
       "  'latitude',\n",
       "  'housing_median_age',\n",
       "  'total_rooms',\n",
       "  'total_bedrooms',\n",
       "  'population',\n",
       "  'households',\n",
       "  'median_income'],\n",
       " 'categorical_columns': ['ocean_proximity'],\n",
       " 'target_column': 'median_house_value',\n",
       " 'domain_value': {'ocean_proximity': ['<1H OCEAN',\n",
       "   'INLAND',\n",
       "   'ISLAND',\n",
       "   'NEAR BAY',\n",
       "   'NEAR OCEAN']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_file_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = train_data.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dtypes = train_data.dtypes\n",
    "column_dtypes =  dict(column_dtypes)\n",
    "str(column_dtypes[\"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_column_dtypes = []\n",
    "for column in columns:\n",
    "    _column_dtypes.append(str(column_dtypes[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'object']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_column_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same number of columns\n"
     ]
    }
   ],
   "source": [
    "if len(schema_file_obj[\"columns\"]) == len(columns):\n",
    "    print(\"same number of columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_len = schema_file_obj[\"columns\"].keys()\n",
    "column_len = list(column_len)\n",
    "for i in range(len(column_len)):\n",
    "    if columns[i] not in column_len:\n",
    "        print(\"something is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longitude': 'float',\n",
       " 'latitude': 'float',\n",
       " 'housing_median_age': 'float',\n",
       " 'total_rooms': 'float',\n",
       " 'total_bedrooms': 'float',\n",
       " 'population': 'float',\n",
       " 'households': 'float',\n",
       " 'median_income': 'float',\n",
       " 'median_house_value': 'float',\n",
       " 'ocean_proximity': 'category'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dtype = schema_file_obj[\"columns\"]\n",
    "_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chech_dtyepes= dict(zip(columns,_column_dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longitude': 'float64',\n",
       " 'latitude': 'float64',\n",
       " 'housing_median_age': 'float64',\n",
       " 'total_rooms': 'float64',\n",
       " 'total_bedrooms': 'float64',\n",
       " 'population': 'float64',\n",
       " 'households': 'float64',\n",
       " 'median_income': 'float64',\n",
       " 'median_house_value': 'float64',\n",
       " 'ocean_proximity': 'object'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chech_dtyepes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = []\n",
    "for i in columns:\n",
    "    if chech_dtyepes[i] == \"object\":\n",
    "        categorical_col.append(i)\n",
    "        chech_dtyepes[i] = \"category\" \n",
    "    if _dtype[i] not in chech_dtyepes[i]:\n",
    "        print(\"something's wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ocean_proximity': ['INLAND',\n",
       "  'NEAR OCEAN',\n",
       "  '<1H OCEAN',\n",
       "  'NEAR BAY',\n",
       "  'ISLAND']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val = {}\n",
    "for value in categorical_col:\n",
    "    unique_val[value] = list(train_data[value].unique())\n",
    "unique_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ocean_proximity': ['<1H OCEAN',\n",
       "  'INLAND',\n",
       "  'ISLAND',\n",
       "  'NEAR BAY',\n",
       "  'NEAR OCEAN']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = schema_file_obj[\"domain_value\"]\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in values:\n",
    "    for check_values in values[value]:\n",
    "        if check_values not in unique_val[value]:\n",
    "            print(f\"something's wrong in {value} column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'median_house_value']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_col = []\n",
    "for i in chech_dtyepes.keys():\n",
    "    if \"float\" in chech_dtyepes[i] or \"int\" in chech_dtyepes[i]:\n",
    "        numerical_col.append(i)\n",
    "numerical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': {'longitude': 'float64',\n",
       "  'latitude': 'float64',\n",
       "  'housing_median_age': 'float64',\n",
       "  'total_rooms': 'float64',\n",
       "  'total_bedrooms': 'float64',\n",
       "  'population': 'float64',\n",
       "  'households': 'float64',\n",
       "  'median_income': 'float64',\n",
       "  'median_house_value': 'float64',\n",
       "  'ocean_proximity': 'category'},\n",
       " 'numerical_col': ['longitude',\n",
       "  'latitude',\n",
       "  'housing_median_age',\n",
       "  'total_rooms',\n",
       "  'total_bedrooms',\n",
       "  'population',\n",
       "  'households',\n",
       "  'median_income',\n",
       "  'median_house_value'],\n",
       " 'categorical_col': ['ocean_proximity'],\n",
       " 'domain_value': {'ocean_proximity': ['INLAND',\n",
       "   'NEAR OCEAN',\n",
       "   '<1H OCEAN',\n",
       "   'NEAR BAY',\n",
       "   'ISLAND']}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtained_obj = {\"columns\":chech_dtyepes,\"numerical_col\":numerical_col,\"categorical_col\":categorical_col,\"domain_value\":unique_val}\n",
    "obtained_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obtain_obj(dataset):\n",
    "    columns = dataset.columns\n",
    "    column_dtypes = dict(dataset.dtypes)\n",
    "    numerical_col = []\n",
    "    categorical_col = []\n",
    "    for i in column_dtypes:\n",
    "        column_dtypes[i] = str(column_dtypes[i])\n",
    "        if \"float\" in column_dtypes[i] or \"int\" in column_dtypes[i]:\n",
    "            numerical_col.append(i)\n",
    "        elif \"object\" in column_dtypes[i]:\n",
    "            column_dtypes[i] = \"category\"\n",
    "            categorical_col.append(i)\n",
    "    domain_value = {}\n",
    "    for value in categorical_col:\n",
    "        domain_value[value] = list(dataset[value].unique())\n",
    "    obtained_obj = {\"columns\":column_dtypes,\"numerical_column\":numerical_col,\"categorical_column\":categorical_col,\"domain_value\":domain_value}\n",
    "    return obtained_obj\n",
    "\n",
    "obtained_train_obj = get_obtain_obj(train_data)\n",
    "obtained_test_obj = get_obtain_obj(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something random'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    l = []\n",
    "    l.append(\"something different\")\n",
    "l = \"something random\"\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longitude': 'float64',\n",
       " 'latitude': 'float64',\n",
       " 'housing_median_age': 'float64',\n",
       " 'total_rooms': 'float64',\n",
       " 'total_bedrooms': 'float64',\n",
       " 'population': 'float64',\n",
       " 'households': 'float64',\n",
       " 'median_income': 'float64',\n",
       " 'median_house_value': 'float64',\n",
       " 'ocean_proximity': 'object'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtained_train_obj[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation for train data that has been done are\n",
      "    1. Same number of column in schema and train data\n",
      "    2. The column names and data types are same in schema and train data\n",
      "    3. The numerical and categorical column are same in both schema and train data\n",
      "    4. The domain values are same for each categorical column in schema and train data\n",
      "    \n",
      "The validation for test data that has been done are\n",
      "    1. Same number of column in schema and test data\n",
      "    2. The column names and data types are same in schema and test data\n",
      "    3. The numerical and categorical column are same in both schema and test data\n",
      "    4. The domain values are same for each categorical column in schema and test data\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def compare_schema_to_dataset(schema_file_obj,obtained_obj,params):\n",
    "    #checking the number of columns\n",
    "    if len(schema_file_obj[\"columns\"]) != len(obtained_obj[\"columns\"]):\n",
    "        return f\"schema file and {params} data set do not have same number of columns\"\n",
    "\n",
    "    #checking the name of the columns and checking the data types of the column\n",
    "    for val in schema_file_obj[\"columns\"].keys():\n",
    "        if val not in obtained_obj[\"columns\"].keys():\n",
    "            return f\"{val} not present in {params} data\"\n",
    "        schema_type = schema_file_obj[\"columns\"][val]\n",
    "        obtain_type = obtained_obj[\"columns\"][val]\n",
    "        if schema_type not in obtain_type:\n",
    "            return f\"{val} is present in {params} data but data types {schema_type} do not match with {obtain_type}\"\n",
    "        if \"float\" in schema_type or \"int\" in schema_type:\n",
    "            if val not in obtained_obj[\"numerical_column\"]:\n",
    "                return f\"{val} is present in {params} data and data types {schema_type} also match with {obtain_type} but {val} is {schema_type} column and still not present in {obtained_obj['numerical_column']}\"\n",
    "        if \"categorical\" in schema_type:\n",
    "            if val not in obtained_obj[\"categorical_column\"]:\n",
    "                return f\"{val} is present in {params} data and data types {schema_type} also match with {obtain_type} but {val} is {schema_type} column and still not present in {obtained_obj['categorical_column']}\"\n",
    "\n",
    "    #to check domain value in categorical columns\n",
    "    cat_col = schema_file_obj[\"categorical_columns\"]\n",
    "    domain_value = schema_file_obj[\"domain_value\"]\n",
    "    for value in cat_col:\n",
    "        for d_value in domain_value[value]:\n",
    "            if d_value not in obtained_obj[\"domain_value\"][value]:\n",
    "                return f\"{d_value} is not described in {obtained_obj['domain_value'][value]} of {val} column of {params} data\"\n",
    "\n",
    "    return f\"\"\"The validation for {params} data that has been done are\n",
    "    1. Same number of column in schema and {params} data\n",
    "    2. The column names and data types are same in schema and {params} data\n",
    "    3. The numerical and categorical column are same in both schema and {params} data\n",
    "    4. The domain values are same for each categorical column in schema and {params} data\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "def check_data_validation(schema_file_obj,obtained_train_obj,obtained_test_obj):\n",
    "    #checking for number of columns\n",
    "    print(compare_schema_to_dataset(schema_file_obj,obtained_train_obj,\"train\"))\n",
    "    print(compare_schema_to_dataset(schema_file_obj,obtained_test_obj,\"test\")) \n",
    "check_data_validation(schema_file_obj,obtained_train_obj,obtained_test_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1762875d695c3b8ce31fc2c385c40c45ae7c7b01a87f50658d419512c57bca88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
